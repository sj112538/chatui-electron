{
  "gpt-3.5-turbo": {
    "type": "chatCompletion",
    "info": {
      "en": "Most capable GPT-3.5 model and optimized for chat at 1/10th the cost of text-davinci-003. Will be updated with our latest model iteration.",
      "zh": "能力最强的GPT-3.5模型,相比于text-davinci-003成本缩减到其的1/10,这个模型将持续迭代升级"
    },
    "version": "GPT-3.5",
    "max_tokens": 4096
  },
  "gpt-3.5-turbo-0301": {
    "type": "chatCompletion",
    "info": {
      "en": "Snapshot of gpt-3.5-turbo from March 1st 2023. Unlike gpt-3.5-turbo, this model will not receive updates, and will only be supported for a three month period ending on June 1st 2023.",
      "zh": "2023年3月1日gpt-3.5-turbo的快照,不同于,这个模型将不再受到更新，该模型的支持截止于2023年6月1日。”"
    },
    "version": "GPT-3.5",
    "max_tokens": 4096
  },
  "text-davinci-003": {
    "type": "completion",
    "info": {
      "en": "Can do any language task with better quality, longer output, and consistent instruction-following than the curie, babbage, or ada models. Also supports inserting completions within text.",
      "zh": "Curie、Babbage或Ada模型更好地完成各种语言任务，输出更长、质量更高，并保持一贯准确地遵循指令。另外，还能在文本中插入补全以保证完整性和连贯性。"
    },
    "version": "GPT-3.5",
    "max_tokens": 4097
  },
  "text-davinci-002": {
    "type": "completion",
    "info": {
      "en": "Similar capabilities to text-davinci-003 but trained with supervised fine-tuning instead of reinforcement learning",
      "zh": "与text-davinci-003类似的功能，但训练方式为受监督的微调，而非强化学习。"
    },
    "version": "GPT-3.5",
    "max_tokens": 4097
  },
  "code-davinci-002": {
    "type": "completion",
    "info": {
      "en": "Optimized for code-completion tasks",
      "zh": "针对代码生成进行优化"
    },
    "version": "GPT-3.5",
    "max_tokens": 8001
  },
  "davinci:2020-05-03": {
    "type": "completion",
    "info": {
      "en": "Optimized for code-completion tasks",
      "zh": "针对代码生成进行优化"
    },
    "version": "GPT-3.5",
    "max_tokens": 8001
  }
}